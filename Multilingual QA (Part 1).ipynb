{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35ba501",
   "metadata": {},
   "source": [
    "# Multilingual QA (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2dc72d-2bea-46d8-8644-50b8e28da144",
   "metadata": {},
   "source": [
    "This Multilingual QA has implemented with **multilingual embedding** model.\n",
    "\n",
    "Steps:\n",
    "1. The data preparation contains PDF data loading, text splitting.\n",
    "2. Document embedding uses multilingual model.\n",
    "3. Created Faiss vector store and embedded documents are inserted in the vector store.\n",
    "4. The retrieval process is implemented with multilingual query.\n",
    "5. For same query, answer is generated using gemini model ensuring language stays consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcc7aa32-7add-4346-9208-ffac63dcd352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_community langchain langchain-google-genai faiss-cpu pdfplumber sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3dec2d-7978-4534-81a5-2f72cbb8ce69",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581ab454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "import faiss\n",
    "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25655cbc-cf29-4f0d-894f-a3d55633950c",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "977e8915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of chunks:  53\n"
     ]
    }
   ],
   "source": [
    "# loading pdf data and chunking\n",
    "\n",
    "pdf_data = PDFPlumberLoader(\"./sample_data/2306.04542v3.pdf\").load()\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "data_splits = splitter.split_documents(pdf_data)\n",
    "print(\"no of chunks: \", len(data_splits))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c0e2e1-b8d1-4517-9c9a-4f0a684998c6",
   "metadata": {},
   "source": [
    "## Document Embedding and vector store generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71ce3041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\AppData\\Local\\Temp\\ipykernel_13832\\845885515.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# multilingual huggingface embedding model\n",
    "model_name = \"Alibaba-NLP/gte-multilingual-base\"\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=model_name,\n",
    "                model_kwargs={\"device\": \"cpu\", \"trust_remote_code\": True},\n",
    "                encode_kwargs={\"normalize_embeddings\": True},\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5225444a-932b-4e7b-ba1d-fe33b54387ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create faiss vectorstore\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=faiss.IndexFlatL2(768),\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "# print(vector_store)\n",
    "vector_store.add_documents(documents=data_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5de6667f-5b82-4032-8de5-646a443b5526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store.save_local('faiss_index_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04412d6-d903-4c73-b6d2-1f0acafd5c34",
   "metadata": {},
   "source": [
    "## Multilingual Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fce07d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multilingual retriever\n",
    "multilingual_retriever = vector_store.as_retriever()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f503dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilingual query\n",
    "query = \"Que se passe-t-il dans le processus avancé du modèle de diffusion ?\"\n",
    "out_docs = multilingual_retriever.invoke(query)\n",
    "context = \"\\n--\\n\".join(doc.page_content for doc in out_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40675194-dafc-4db2-b22e-65ad8a9dccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval output for multilingual embedding model: \n",
      "\n",
      "Document:  [274],Chemistry[275],[276],etc.Theyarenotonlyapplying\n",
      "and adapting diffusion models to solve problems in these\n",
      "domains,butalsoleveragingknowledgeinadisciplinaryto\n",
      "theoretically improve diffusion model\n",
      "****************************************************************************************************\n",
      "Document:  each timestep. The reverse process moves on the chain in pling procedure, as shown in Figure 1. This breakdown is\n",
      "the opposite direction. It optimizes a network to remove aligned with the generic pipe\n",
      "****************************************************************************************************\n",
      "Document:  1\n",
      "On the Design Fundamentals of\n",
      "Diffusion Models: A Survey\n",
      "Ziyi Chang, George Koulieris, Hubert P. H. Shum, Senior Member, IEEE\n",
      "Abstract—Diffusionmodelsaregenerativemodels,whichgraduallyaddandremoveno\n",
      "****************************************************************************************************\n",
      "Document:  2\n",
      "Fig.1.Theoverviewofdiffusionmodels.Theforwardprocess,thereverseprocess,andthesamplingprocedurearethethreecorecomponentsof\n",
      "diffusionmodels,whichareresponsibleforaddingnoise,trainingnetworks,andgenera\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"Retrieval output for multilingual embedding model: \\n\")\n",
    "for doc in out_docs :\n",
    "    print(\"Document: \", doc.page_content[0:200])\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6889442c-3e80-4d1e-b6ac-4af5f536e7f2",
   "metadata": {},
   "source": [
    "## Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b30ce86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key=\"google_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12f1a71e-da12-4078-aa73-91c21d39a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"You are a multilingual assistant. Answer user's {query} from given {context} in same language as query.\")\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({'query': query,\n",
    "                            'context': context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3060828f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: \n",
      " Que se passe-t-il dans le processus avancé du modèle de diffusion ?\n",
      "response: \n",
      " Le processus de diffusion avancé implique une compréhension approfondie de la façon dont le bruit est progressivement ajouté à un échantillon de données dans le processus de diffusion directe, puis supprimé dans le processus inverse pour générer de nouvelles données. \n",
      "\n",
      "En termes simples, imaginez une goutte d'encre dans un verre d'eau. \n",
      "\n",
      "1. **Processus de diffusion direct (ajout de bruit):**  C'est comme si l'on regardait l'encre se diffuser lentement dans l'eau. À chaque étape, l'encre se répand un peu plus, devenant de plus en plus \"bruyante\" jusqu'à ce qu'elle soit uniformément répartie et que l'on ne puisse plus distinguer la goutte d'origine.\n",
      "\n",
      "2. **Processus de diffusion inverse (suppression du bruit):** C'est là que ça devient intéressant. Le modèle apprend à inverser ce processus de diffusion. Il apprend à \"dé-mélanger\" l'encre, étape par étape, en commençant par l'état \"bruyant\" final et en remontant jusqu'à l'état initial de la goutte d'encre.\n",
      "\n",
      "Le processus avancé consiste à entraîner un réseau neuronal à comprendre et à reproduire ce processus de \"dé-mélange\" de l'encre.  Une fois entraîné, le modèle peut générer de nouvelles données en partant d'un état \"bruyant\" et en le \"dé-bruyant\" progressivement pour créer quelque chose de nouveau et cohérent.\n",
      "\n",
      "En résumé, le processus de diffusion avancé permet de capturer la structure sous-jacente des données en apprenant à la fois à ajouter et à supprimer du bruit de manière contrôlée.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"query: \\n\",query)\n",
    "print(\"response: \\n\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c14ca95-d41c-4b65-940f-575e2d8de584",
   "metadata": {},
   "source": [
    "**Translated output:**\n",
    "\n",
    "The advanced diffusion process involves a thorough understanding of how noise is progressively added to a data sample in the forward diffusion process and then removed in the reverse process to generate new data. \n",
    "\n",
    "In simple terms, imagine a drop of ink in a glass of water. \n",
    "\n",
    "1. **Direct diffusion process (adding noise):** It's like watching ink slowly diffuse in water. With each step, the ink spreads a little more, becoming more and more \"noisy\" until it is evenly distributed and you can no longer make out the original drop.\n",
    "\n",
    "2. **Reverse diffusion process (noise removal):** This is where it gets interesting. The model learns to reverse this diffusion process. It learns how to \"un-mix\" the ink, step by step, starting with the final \"noisy\" state and working back to the initial state of the ink drop.\n",
    "\n",
    "The advanced process involves training a neural network to understand and replicate this ink “un-mixing” process.  Once trained, the model can generate new data by starting from a “noisy” state and gradually “de-noising” it to create something new and coherent.\n",
    "\n",
    "In summary, the advanced streaming process helps capture the underlying structure of data by learning to both add and remove noise in a controlled manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c8a6f0-466f-4ac3-9ee6-4a3f7e53f9fa",
   "metadata": {},
   "source": [
    "# Multilingual Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d80f680-f0b7-4aa1-a615-9340475e0fa0",
   "metadata": {},
   "source": [
    "* The multilingual embeddings are used with multilingual documents. The document is having french and german data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f55ae36-690d-424f-ae0e-04acb6c1c5d7",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0741ba3-16c7-4b46-bd7c-96bcef8689db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of chunks:  7\n"
     ]
    }
   ],
   "source": [
    "# loading multilingual data and chunking\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "text_data = TextLoader(\",/sample_data/multilingual_text.txt\").load()\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "data_splits = splitter.split_documents(text_data)\n",
    "print(\"no of chunks: \", len(data_splits))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da756ea1-0b2f-40de-9223-af9e4b0924ac",
   "metadata": {},
   "source": [
    "## Multilingual embedding and vector store generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa96ea64-816f-42c1-acaf-df854a8d9d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooja\\AppData\\Local\\Temp\\ipykernel_13464\\845885515.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# multilingual huggingface embedding model\n",
    "model_name = \"Alibaba-NLP/gte-multilingual-base\"\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=model_name,\n",
    "                model_kwargs={\"device\": \"cpu\", \"trust_remote_code\": True},\n",
    "                encode_kwargs={\"normalize_embeddings\": True},\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a0fad0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f7d6d487-08bd-423d-987d-2084f5f08242',\n",
       " 'afc3fec4-9d65-4b05-bbd8-791739b7c276',\n",
       " '003f21c3-4b6a-4cd7-8b8b-09cca3fd2626',\n",
       " 'c2d92a07-8cae-4a81-8e8b-7863e9f8c967',\n",
       " '11cfc88f-39c1-46f5-bda7-cab4c7d6427c',\n",
       " '72bd6ccf-97af-4188-a84b-885eb95a8925',\n",
       " '7115b853-e195-44ce-8684-da955e02807f']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create faiss vectorstore\n",
    "vector_store1 = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=faiss.IndexFlatL2(768),\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "# print(vector_store)\n",
    "vector_store1.add_documents(documents=data_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a049a0-ab26-4e0a-98fb-4088523d7e13",
   "metadata": {},
   "source": [
    "## Mutlitlingual Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f05d555-b51f-40a3-9dd6-362c72233eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multilingual retriever\n",
    "multilingual_doc_retriever = vector_store1.as_retriever()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "581dbb6e-1e3a-4c32-91be-d8f1c583a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilingual query\n",
    "query = \"wat is die verskil tussen GAN'e en diffusiemodel?\"\n",
    "out_docs = multilingual_doc_retriever.invoke(query)\n",
    "context = \"\\n--\\n\".join(doc.page_content for doc in out_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60973803-729f-4c24-94af-581f087a1b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval output for multilingual embedding model: \n",
      "\n",
      "Document:  Evolution von Diffusionsmodellen aus GANs\n",
      "Generative Adversarial Networks (GANs) und Diffusionsmodelle sind zwei wichtige Techniken im Bereich der generativen Modellierung, jede mit ihren eigenen StÃ¤\n",
      "****************************************************************************************************\n",
      "Document:  Funktionsweise von Diffusionsmodellen\n",
      "\n",
      "VorwÃ¤rtsprozess: Saubere Daten werden in mehreren Schritten mit Rauschen verfÃ¤lscht.\n",
      "RÃ¼ckwÃ¤rtsprozess: Ein neuronales Netzwerk lernt, den Rauschprozess umzuk\n",
      "****************************************************************************************************\n",
      "Document:  Export to Sheets\n",
      "Fazit\n",
      "WÃ¤hrend GANs einen bedeutenden Meilenstein in der generativen Modellierung darstellen, haben sich Diffusionsmodelle als vielversprechende Alternative mit mehreren Vorteilen her\n",
      "****************************************************************************************************\n",
      "Document:  RÃ©seaux Adversariaux GÃ©nÃ©ratifs (GANs) : Une PlongÃ©e Profonde\n",
      "Introduction\n",
      "\n",
      "Les RÃ©seaux Adversariaux GÃ©nÃ©ratifs (GANs) sont une classe de frameworks d'apprentissage automatique conÃ§us par Ian \n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"Retrieval output for multilingual embedding model: \\n\")\n",
    "for doc in out_docs :\n",
    "    print(\"Document: \", doc.page_content[0:200])\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e2ce1e-e6ea-48ec-8822-87fcdaebffe5",
   "metadata": {},
   "source": [
    "## Quetion Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "694f2025-b49c-4d62-9242-e743d08d4f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key=\"google_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d392a8a4-82bc-45aa-812b-25852d383e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"You are a multilingual assistant. Answer user's {query} from given {context} in same language as query.\")\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({'query': query,\n",
    "                            'context': context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a22ebbb9-af9f-4c97-a91e-4500845dbcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: \n",
      " wat is die verskil tussen GAN'e en diffusiemodel?\n",
      "response: \n",
      " Die verskil tussen GAN'e (Generatiewe Teenstander Netwerke) en diffusiemodelle lê in hoe hulle werk:\n",
      "\n",
      "**GAN'e:**\n",
      "\n",
      "* **Twee netwerke:** 'n Generator wat probeer om vals data te skep, en 'n diskrimineerder wat probeer om te onderskei tussen werklike en vals data. Hulle \"veg\" teen mekaar, wat die generator beter maak met tyd.\n",
      "* **Voorbeeld:** Dink aan 'n vervalser wat probeer om 'n skildery na te maak, en 'n kunskenner wat probeer om die vervalsing te identifiseer.\n",
      "* **Voordele:** Kan baie realistiese data skep.\n",
      "* **Nadele:** Kan onstabiel wees om te oefen, en kan sukkel om diverse data te skep.\n",
      "\n",
      "**Diffusiemodelle:**\n",
      "\n",
      "* **Een netwerk:** 'n Enkele netwerk wat leer om geraas by data te voeg en dit dan weer te verwyder. Deur hierdie proses te keer, kan dit nuwe data genereer.\n",
      "* **Voorbeeld:** Dink aan 'n glas water waar jy ink byvoeg en dit dan stadig verwyder totdat jy skoon water oor het. Die model leer hoe om die \"ink\" (geraas) by te voeg en te verwyder.\n",
      "* **Voordele:** Meer stabiel om te oefen, en kan meer diverse data skep.\n",
      "* **Nadele:** Kan stadiger wees om te genereer as GAN'e.\n",
      "\n",
      "**In kort:** GAN'e is soos twee kunstenaars wat teen mekaar meeding, terwyl diffusiemodelle soos 'n enkele kunstenaar is wat leer om 'n beeld te ontrafel en weer saam te stel. Beide kan gebruik word om indrukwekkende resultate te behaal, maar het verskillende sterk- en swakpunte.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"query: \\n\",query)\n",
    "print(\"response: \\n\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f03699-a862-4198-b33b-12222e28efdb",
   "metadata": {},
   "source": [
    "The difference between GANs (Generative Adversary Networks) and diffusion models lies in how they work:\n",
    "\n",
    "**GANs:**\n",
    "\n",
    "* **Two networks:** A generator that tries to create fake data, and a discriminator that tries to distinguish between real and fake data. They \"fight\" against each other, making the generator better with time.\n",
    "* **Example:** Consider a forger trying to fake a painting, and an art connoisseur trying to identify the forgery.\n",
    "* **Advantages:** Can create very realistic data.\n",
    "* **Disadvantages:** Can be unstable to train, and can struggle to create diverse data.\n",
    "\n",
    "**Diffusion models:**\n",
    "\n",
    "* **One network:** A single network that learns to add noise to data and then remove it again. By stopping this process, it can generate new data.\n",
    "* **Example:** Think of a glass of water where you add ink and then slowly remove it until you are left with clear water. The model learns how to add and remove the \"ink\" (noise).\n",
    "* **Advantages:** More stable to train, and can create more diverse data.\n",
    "* **Disadvantages:** Can be slower to generate than GANs.\n",
    "\n",
    "**In short:** GANs are like two artists competing against each other, while diffusion models are like a single artist learning to unravel and reassemble an image. Both can be used to achieve impressive results, but have different strengths and weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4462257e-9940-44f0-9a6b-2ca2e3757869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
